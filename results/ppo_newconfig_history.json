{
  "training": [
    {
      "episodes_completed": 28,
      "mean_reward": 341.7818214285714,
      "std_reward": 544.3345255968229,
      "steps_collected": 2048,
      "policy_loss": -0.005414934549480677,
      "value_loss": 11940.936534118653,
      "entropy": 1.973076320067048,
      "total_loss": 5970.443131256104,
      "training_step": 1,
      "epoch": 0,
      "elapsed_time": 7.483837127685547
    },
    {
      "episodes_completed": 34,
      "mean_reward": 294.84491176470584,
      "std_reward": 448.8395052134525,
      "steps_collected": 2048,
      "policy_loss": -0.002924120333045721,
      "value_loss": 9508.393470001221,
      "entropy": 1.9871362883597612,
      "total_loss": 4754.173949432373,
      "training_step": 2,
      "epoch": 1,
      "elapsed_time": 15.97029185295105
    },
    {
      "episodes_completed": 34,
      "mean_reward": 282.13144117647056,
      "std_reward": 345.0224708778521,
      "steps_collected": 2048,
      "policy_loss": 0.045580906647956,
      "value_loss": 5824.655433654785,
      "entropy": 1.9680847525596619,
      "total_loss": 2912.3536121368406,
      "training_step": 3,
      "epoch": 2,
      "elapsed_time": 24.465753078460693
    },
    {
      "episodes_completed": 32,
      "mean_reward": 234.34890624999994,
      "std_reward": 298.87848773857485,
      "steps_collected": 2048,
      "policy_loss": 0.02812566170177888,
      "value_loss": 5699.4845565795895,
      "entropy": 1.971821529790759,
      "total_loss": 2849.750680541992,
      "training_step": 4,
      "epoch": 3,
      "elapsed_time": 32.764508962631226
    },
    {
      "episodes_completed": 25,
      "mean_reward": 396.4682799999999,
      "std_reward": 556.4666186869085,
      "steps_collected": 2048,
      "policy_loss": 0.00473722574824933,
      "value_loss": 8768.6755859375,
      "entropy": 1.8865148536860943,
      "total_loss": 4384.323681259155,
      "training_step": 5,
      "epoch": 4,
      "elapsed_time": 41.07485628128052
    },
    {
      "episodes_completed": 29,
      "mean_reward": 295.7081034482758,
      "std_reward": 395.661613870981,
      "steps_collected": 2048,
      "policy_loss": 0.02078679415717488,
      "value_loss": 8677.639726257325,
      "entropy": 1.8801135074347257,
      "total_loss": 4338.821852874756,
      "training_step": 6,
      "epoch": 5,
      "elapsed_time": 49.388763427734375
    },
    {
      "episodes_completed": 29,
      "mean_reward": 369.57937931034456,
      "std_reward": 509.70984776184923,
      "steps_collected": 2048,
      "policy_loss": 0.008452148499782198,
      "value_loss": 11314.275289916992,
      "entropy": 1.8532759577035904,
      "total_loss": 5657.127555847168,
      "training_step": 7,
      "epoch": 6,
      "elapsed_time": 57.80079627037048
    },
    {
      "episodes_completed": 25,
      "mean_reward": 350.6380799999999,
      "std_reward": 328.4082677769144,
      "steps_collected": 2048,
      "policy_loss": 0.003612546532531269,
      "value_loss": 8771.629907226563,
      "entropy": 1.859157382696867,
      "total_loss": 4385.799976348877,
      "training_step": 8,
      "epoch": 7,
      "elapsed_time": 66.09760808944702
    },
    {
      "episodes_completed": 26,
      "mean_reward": 380.0496538461538,
      "std_reward": 467.3411818662563,
      "steps_collected": 2048,
      "policy_loss": 0.007013112303684466,
      "value_loss": 9619.412113952636,
      "entropy": 1.8313437793403864,
      "total_loss": 4809.6947593688965,
      "training_step": 9,
      "epoch": 8,
      "elapsed_time": 74.39885926246643
    },
    {
      "episodes_completed": 27,
      "mean_reward": 338.1368518518517,
      "std_reward": 347.18783750850173,
      "steps_collected": 2048,
      "policy_loss": 0.017028277454664932,
      "value_loss": 10122.395703125,
      "entropy": 1.7858293283730746,
      "total_loss": 5061.197036743164,
      "training_step": 10,
      "epoch": 9,
      "elapsed_time": 82.70023703575134
    },
    {
      "episodes_completed": 20,
      "mean_reward": 545.6772999999998,
      "std_reward": 356.69368773852716,
      "steps_collected": 2048,
      "policy_loss": 0.018468958130688405,
      "value_loss": 9640.420121765137,
      "entropy": 1.798979077860713,
      "total_loss": 4820.21053237915,
      "training_step": 11,
      "epoch": 10,
      "elapsed_time": 91.05038738250732
    },
    {
      "episodes_completed": 18,
      "mean_reward": 480.87305555555537,
      "std_reward": 380.5510414957458,
      "steps_collected": 2048,
      "policy_loss": 0.011513966010534204,
      "value_loss": 9184.597979736329,
      "entropy": 1.5827424127608538,
      "total_loss": 4592.294664764404,
      "training_step": 12,
      "epoch": 11,
      "elapsed_time": 99.51983952522278
    },
    {
      "episodes_completed": 25,
      "mean_reward": 417.1033199999998,
      "std_reward": 373.0595386004457,
      "steps_collected": 2048,
      "policy_loss": 0.01818556567886844,
      "value_loss": 9134.297206115723,
      "entropy": 1.5523342572152614,
      "total_loss": 4567.151259613037,
      "training_step": 13,
      "epoch": 12,
      "elapsed_time": 107.96457481384277
    },
    {
      "episodes_completed": 26,
      "mean_reward": 398.3205384615382,
      "std_reward": 505.01013387701335,
      "steps_collected": 2048,
      "policy_loss": 0.012279818160459399,
      "value_loss": 9777.449000549317,
      "entropy": 1.4043155010789632,
      "total_loss": 4888.722722625733,
      "training_step": 14,
      "epoch": 13,
      "elapsed_time": 116.31535696983337
    },
    {
      "episodes_completed": 24,
      "mean_reward": 479.02470833333314,
      "std_reward": 542.2939928666059,
      "steps_collected": 2048,
      "policy_loss": 0.010217501857550815,
      "value_loss": 9905.670767211914,
      "entropy": 1.322598334774375,
      "total_loss": 4952.832387542725,
      "training_step": 15,
      "epoch": 14,
      "elapsed_time": 124.66724181175232
    },
    {
      "episodes_completed": 28,
      "mean_reward": 403.4516785714283,
      "std_reward": 437.99253948669434,
      "steps_collected": 2048,
      "policy_loss": 0.0018888730090111494,
      "value_loss": 10873.549380493165,
      "entropy": 1.3193181861191987,
      "total_loss": 5436.763382720947,
      "training_step": 16,
      "epoch": 15,
      "elapsed_time": 132.98363733291626
    },
    {
      "episodes_completed": 21,
      "mean_reward": 533.0722380952377,
      "std_reward": 502.0887853016685,
      "steps_collected": 2048,
      "policy_loss": 0.0031605531461536885,
      "value_loss": 9061.285037231446,
      "entropy": 1.2950605992227793,
      "total_loss": 4530.632731628418,
      "training_step": 17,
      "epoch": 16,
      "elapsed_time": 141.27018022537231
    },
    {
      "episodes_completed": 22,
      "mean_reward": 570.203954545454,
      "std_reward": 559.2985968637596,
      "steps_collected": 2048,
      "policy_loss": 0.006127994367852807,
      "value_loss": 10344.266778564453,
      "entropy": 1.2969633724540472,
      "total_loss": 5172.126535797119,
      "training_step": 18,
      "epoch": 17,
      "elapsed_time": 149.54307508468628
    },
    {
      "episodes_completed": 31,
      "mean_reward": 382.0059999999999,
      "std_reward": 601.5440573209322,
      "steps_collected": 2048,
      "policy_loss": 7.759987202007323e-05,
      "value_loss": 15498.857373046874,
      "entropy": 1.2357232104986906,
      "total_loss": 7749.416410827636,
      "training_step": 19,
      "epoch": 18,
      "elapsed_time": 157.8250765800476
    },
    {
      "episodes_completed": 23,
      "mean_reward": 495.57443478260836,
      "std_reward": 517.1663870786506,
      "steps_collected": 2048,
      "policy_loss": 0.004378433682722971,
      "value_loss": 11916.303538513184,
      "entropy": 1.3018426772207021,
      "total_loss": 5958.143140411377,
      "training_step": 20,
      "epoch": 19,
      "elapsed_time": 166.24835443496704
    },
    {
      "episodes_completed": 30,
      "mean_reward": 383.96459999999996,
      "std_reward": 360.7222644572597,
      "steps_collected": 2048,
      "policy_loss": 0.003506509953876957,
      "value_loss": 12106.337338256835,
      "entropy": 1.1728629674762487,
      "total_loss": 6053.160417175293,
      "training_step": 21,
      "epoch": 20,
      "elapsed_time": 176.2983100414276
    },
    {
      "episodes_completed": 26,
      "mean_reward": 413.7371538461535,
      "std_reward": 396.9283014628797,
      "steps_collected": 2048,
      "policy_loss": 0.003479787637479603,
      "value_loss": 10633.613777160645,
      "entropy": 1.150557895563543,
      "total_loss": 5316.798866271973,
      "training_step": 22,
      "epoch": 21,
      "elapsed_time": 184.98404145240784
    },
    {
      "episodes_completed": 20,
      "mean_reward": 642.5435999999996,
      "std_reward": 479.57189083279235,
      "steps_collected": 2048,
      "policy_loss": 0.013341164187295362,
      "value_loss": 10671.960508728027,
      "entropy": 1.012041494064033,
      "total_loss": 5335.983460235596,
      "training_step": 23,
      "epoch": 22,
      "elapsed_time": 193.28026413917542
    },
    {
      "episodes_completed": 27,
      "mean_reward": 469.2079259259256,
      "std_reward": 580.9858612053418,
      "steps_collected": 2048,
      "policy_loss": 0.007536586062633433,
      "value_loss": 12794.142791748047,
      "entropy": 0.9317905219271779,
      "total_loss": 6397.069622039795,
      "training_step": 24,
      "epoch": 23,
      "elapsed_time": 201.59420657157898
    },
    {
      "episodes_completed": 30,
      "mean_reward": 287.49543333333327,
      "std_reward": 285.4014828442769,
      "steps_collected": 2048,
      "policy_loss": -0.0011144139571115375,
      "value_loss": 8177.306095123291,
      "entropy": 0.9248974848538637,
      "total_loss": 4088.6426776885987,
      "training_step": 25,
      "epoch": 24,
      "elapsed_time": 209.9277698993683
    },
    {
      "episodes_completed": 18,
      "mean_reward": 841.2303888888885,
      "std_reward": 423.1960727429016,
      "steps_collected": 2048,
      "policy_loss": 0.010787577964947559,
      "value_loss": 8866.765455627441,
      "entropy": 0.9840744737535715,
      "total_loss": 4433.383672332764,
      "training_step": 26,
      "epoch": 25,
      "elapsed_time": 218.2996368408203
    },
    {
      "episodes_completed": 19,
      "mean_reward": 652.9791052631579,
      "std_reward": 648.5816613966116,
      "steps_collected": 2048,
      "policy_loss": 3.404873423278332e-05,
      "value_loss": 10869.315214538574,
      "entropy": 0.9238549565896392,
      "total_loss": 5434.648397064209,
      "training_step": 27,
      "epoch": 26,
      "elapsed_time": 226.88426756858826
    },
    {
      "episodes_completed": 27,
      "mean_reward": 487.6591111111109,
      "std_reward": 499.37770081634324,
      "steps_collected": 2048,
      "policy_loss": 0.003928061266196892,
      "value_loss": 11919.515838623047,
      "entropy": 0.9064820427447557,
      "total_loss": 5959.752793884278,
      "training_step": 28,
      "epoch": 27,
      "elapsed_time": 235.18382048606873
    },
    {
      "episodes_completed": 26,
      "mean_reward": 513.7476538461535,
      "std_reward": 547.7475910630551,
      "steps_collected": 2048,
      "policy_loss": 0.0025400801852811126,
      "value_loss": 11766.555723571777,
      "entropy": 0.8999600052833557,
      "total_loss": 5883.271410369873,
      "training_step": 29,
      "epoch": 28,
      "elapsed_time": 243.5836865901947
    },
    {
      "episodes_completed": 28,
      "mean_reward": 515.2234642857144,
      "std_reward": 630.3415468832573,
      "steps_collected": 2048,
      "policy_loss": 0.005925249875872396,
      "value_loss": 14632.976287841797,
      "entropy": 0.8970411719754339,
      "total_loss": 7316.485096740723,
      "training_step": 30,
      "epoch": 29,
      "elapsed_time": 251.81971955299377
    },
    {
      "episodes_completed": 29,
      "mean_reward": 457.00831034482735,
      "std_reward": 492.41508161923286,
      "steps_collected": 2048,
      "policy_loss": 0.004061599689885042,
      "value_loss": 12055.091416931153,
      "entropy": 0.9666145481169224,
      "total_loss": 6027.540095520019,
      "training_step": 31,
      "epoch": 30,
      "elapsed_time": 260.38457798957825
    },
    {
      "episodes_completed": 27,
      "mean_reward": 630.4547407407409,
      "std_reward": 752.9001892530667,
      "steps_collected": 2048,
      "policy_loss": 0.02684861805755645,
      "value_loss": 14311.775105285644,
      "entropy": 0.9627737173810601,
      "total_loss": 7155.904802703857,
      "training_step": 32,
      "epoch": 31,
      "elapsed_time": 269.05923676490784
    },
    {
      "episodes_completed": 20,
      "mean_reward": 720.6067999999998,
      "std_reward": 694.6256113862062,
      "steps_collected": 2048,
      "policy_loss": 0.01205506109399721,
      "value_loss": 13739.035743713379,
      "entropy": 0.9777282798662782,
      "total_loss": 6869.520156097412,
      "training_step": 33,
      "epoch": 32,
      "elapsed_time": 277.32450795173645
    },
    {
      "episodes_completed": 22,
      "mean_reward": 680.9099545454543,
      "std_reward": 490.104145529988,
      "steps_collected": 2048,
      "policy_loss": 0.011948163027409465,
      "value_loss": 15351.550262451172,
      "entropy": 0.7846737945452332,
      "total_loss": 7675.779241943359,
      "training_step": 34,
      "epoch": 33,
      "elapsed_time": 285.66999220848083
    },
    {
      "episodes_completed": 32,
      "mean_reward": 363.8431249999999,
      "std_reward": 336.80609130846227,
      "steps_collected": 2048,
      "policy_loss": -0.0013192704849643634,
      "value_loss": 14258.373419189453,
      "entropy": 0.6293056301772595,
      "total_loss": 7129.179105377198,
      "training_step": 35,
      "epoch": 34,
      "elapsed_time": 293.919704914093
    },
    {
      "episodes_completed": 20,
      "mean_reward": 648.3557999999995,
      "std_reward": 420.4360027195097,
      "steps_collected": 2048,
      "policy_loss": 0.003430046804714948,
      "value_loss": 10125.28433380127,
      "entropy": 0.6030815946869552,
      "total_loss": 5062.639562988281,
      "training_step": 36,
      "epoch": 35,
      "elapsed_time": 302.2591531276703
    },
    {
      "episodes_completed": 29,
      "mean_reward": 490.1910344827584,
      "std_reward": 519.2823614881629,
      "steps_collected": 2048,
      "policy_loss": 0.016432576754596084,
      "value_loss": 11866.529063415528,
      "entropy": 0.6365554131567478,
      "total_loss": 5933.274599456787,
      "training_step": 37,
      "epoch": 36,
      "elapsed_time": 310.6285092830658
    },
    {
      "episodes_completed": 27,
      "mean_reward": 431.1866666666665,
      "std_reward": 433.5303234471009,
      "steps_collected": 2048,
      "policy_loss": 0.0078124187479261305,
      "value_loss": 11296.280368041993,
      "entropy": 0.6657361613586545,
      "total_loss": 5648.141333007812,
      "training_step": 38,
      "epoch": 37,
      "elapsed_time": 318.89856243133545
    },
    {
      "episodes_completed": 29,
      "mean_reward": 405.0497586206894,
      "std_reward": 418.90289889141513,
      "steps_collected": 2048,
      "policy_loss": 0.005601158039644361,
      "value_loss": 11946.653317260741,
      "entropy": 0.645024296361953,
      "total_loss": 5973.325796508789,
      "training_step": 39,
      "epoch": 38,
      "elapsed_time": 327.1988081932068
    },
    {
      "episodes_completed": 22,
      "mean_reward": 608.4887727272727,
      "std_reward": 554.5526540171353,
      "steps_collected": 2048,
      "policy_loss": 0.012263948752661236,
      "value_loss": 10178.441554260255,
      "entropy": 0.6394477048888803,
      "total_loss": 5089.226663970947,
      "training_step": 40,
      "epoch": 39,
      "elapsed_time": 335.47067284584045
    },
    {
      "episodes_completed": 28,
      "mean_reward": 437.60728571428547,
      "std_reward": 362.04490303915685,
      "steps_collected": 2048,
      "policy_loss": 0.00607694101636298,
      "value_loss": 10341.354112243653,
      "entropy": 0.6444404011592268,
      "total_loss": 5170.676663970948,
      "training_step": 41,
      "epoch": 40,
      "elapsed_time": 345.25446009635925
    },
    {
      "episodes_completed": 21,
      "mean_reward": 664.7481428571425,
      "std_reward": 644.2490371508067,
      "steps_collected": 2048,
      "policy_loss": 0.008477005956228823,
      "value_loss": 10495.706100463867,
      "entropy": 0.596141759864986,
      "total_loss": 5247.855563354492,
      "training_step": 42,
      "epoch": 41,
      "elapsed_time": 353.51736998558044
    },
    {
      "episodes_completed": 32,
      "mean_reward": 358.8853749999999,
      "std_reward": 441.73790854743186,
      "steps_collected": 2048,
      "policy_loss": -0.0014890596154145896,
      "value_loss": 12608.183280944824,
      "entropy": 0.550243258010596,
      "total_loss": 6304.084641265869,
      "training_step": 43,
      "epoch": 42,
      "elapsed_time": 362.7856843471527
    },
    {
      "episodes_completed": 25,
      "mean_reward": 514.1494399999998,
      "std_reward": 513.2823994870722,
      "steps_collected": 2048,
      "policy_loss": 0.0036247784941224382,
      "value_loss": 10879.787565612793,
      "entropy": 0.6269504849798977,
      "total_loss": 5439.891136169434,
      "training_step": 44,
      "epoch": 43,
      "elapsed_time": 371.13370990753174
    },
    {
      "episodes_completed": 24,
      "mean_reward": 547.6144166666664,
      "std_reward": 439.08122424177924,
      "steps_collected": 2048,
      "policy_loss": 0.004492179182125256,
      "value_loss": 9850.848469543456,
      "entropy": 0.6604222775436938,
      "total_loss": 4925.422123718262,
      "training_step": 45,
      "epoch": 44,
      "elapsed_time": 379.57134437561035
    },
    {
      "episodes_completed": 16,
      "mean_reward": 1070.2263125000004,
      "std_reward": 698.4740922893749,
      "steps_collected": 2048,
      "policy_loss": 0.015730150579474866,
      "value_loss": 13209.179852294921,
      "entropy": 0.6977976400405168,
      "total_loss": 6604.598684692382,
      "training_step": 46,
      "epoch": 45,
      "elapsed_time": 388.18357825279236
    },
    {
      "episodes_completed": 19,
      "mean_reward": 781.0225789473683,
      "std_reward": 701.9849070067654,
      "steps_collected": 2048,
      "policy_loss": 0.00793691054568626,
      "value_loss": 16553.152130126953,
      "entropy": 0.6100869663991034,
      "total_loss": 8276.577905273438,
      "training_step": 47,
      "epoch": 46,
      "elapsed_time": 396.4501965045929
    },
    {
      "episodes_completed": 25,
      "mean_reward": 526.0392399999997,
      "std_reward": 504.236180101133,
      "steps_collected": 2048,
      "policy_loss": 0.01066856500110589,
      "value_loss": 12782.256828308105,
      "entropy": 0.5657429926097393,
      "total_loss": 6391.133414459228,
      "training_step": 48,
      "epoch": 47,
      "elapsed_time": 404.7076997756958
    },
    {
      "episodes_completed": 20,
      "mean_reward": 706.7315499999997,
      "std_reward": 582.5429655728815,
      "steps_collected": 2048,
      "policy_loss": 0.003675341757480055,
      "value_loss": 11460.51665802002,
      "entropy": 0.646567415073514,
      "total_loss": 5730.255532836914,
      "training_step": 49,
      "epoch": 48,
      "elapsed_time": 412.9926702976227
    },
    {
      "episodes_completed": 31,
      "mean_reward": 436.4887741935482,
      "std_reward": 459.6634424652599,
      "steps_collected": 2048,
      "policy_loss": 0.020123177283676342,
      "value_loss": 11920.569621276856,
      "entropy": 0.6762274922803044,
      "total_loss": 5960.298165130615,
      "training_step": 50,
      "epoch": 49,
      "elapsed_time": 421.42095923423767
    },
    {
      "episodes_completed": 34,
      "mean_reward": 403.7620294117645,
      "std_reward": 510.5509780021098,
      "steps_collected": 2048,
      "policy_loss": 0.00809505560901016,
      "value_loss": 14371.21149749756,
      "entropy": 0.656064232531935,
      "total_loss": 7185.607280731201,
      "training_step": 51,
      "epoch": 50,
      "elapsed_time": 430.00191259384155
    },
    {
      "episodes_completed": 21,
      "mean_reward": 689.4236666666665,
      "std_reward": 505.1376875616927,
      "steps_collected": 2048,
      "policy_loss": 0.0026363260287325828,
      "value_loss": 11109.874838256836,
      "entropy": 0.6498279070481658,
      "total_loss": 5554.933576202393,
      "training_step": 52,
      "epoch": 51,
      "elapsed_time": 438.5485475063324
    },
    {
      "episodes_completed": 22,
      "mean_reward": 631.6538181818179,
      "std_reward": 450.2409876378966,
      "steps_collected": 2048,
      "policy_loss": 0.002863286796491593,
      "value_loss": 13097.409091186524,
      "entropy": 0.4987845288589597,
      "total_loss": 6548.702397155762,
      "training_step": 53,
      "epoch": 52,
      "elapsed_time": 446.8589701652527
    },
    {
      "episodes_completed": 25,
      "mean_reward": 525.7944399999997,
      "std_reward": 453.070076487607,
      "steps_collected": 2048,
      "policy_loss": 0.002774241825682111,
      "value_loss": 10845.568562316894,
      "entropy": 0.5423827639780938,
      "total_loss": 5422.781631469727,
      "training_step": 54,
      "epoch": 53,
      "elapsed_time": 455.18743348121643
    },
    {
      "episodes_completed": 19,
      "mean_reward": 834.8549473684209,
      "std_reward": 656.5450232220402,
      "steps_collected": 2048,
      "policy_loss": 0.003628235397627577,
      "value_loss": 15218.22030029297,
      "entropy": 0.5510875620879233,
      "total_loss": 7609.1082862854,
      "training_step": 55,
      "epoch": 54,
      "elapsed_time": 463.52076983451843
    },
    {
      "episodes_completed": 20,
      "mean_reward": 697.9959000000001,
      "std_reward": 667.3271765640078,
      "steps_collected": 2048,
      "policy_loss": 0.01873820543696638,
      "value_loss": 13274.167066955566,
      "entropy": 0.6081669912673533,
      "total_loss": 6637.0961837768555,
      "training_step": 56,
      "epoch": 55,
      "elapsed_time": 471.88389134407043
    },
    {
      "episodes_completed": 24,
      "mean_reward": 517.599083333333,
      "std_reward": 516.5694745435919,
      "steps_collected": 2048,
      "policy_loss": 0.015236000122968107,
      "value_loss": 14061.729066467286,
      "entropy": 0.5525119583122432,
      "total_loss": 7030.8742378234865,
      "training_step": 57,
      "epoch": 56,
      "elapsed_time": 480.1700539588928
    },
    {
      "episodes_completed": 20,
      "mean_reward": 456.7029999999995,
      "std_reward": 439.3347421423662,
      "steps_collected": 2048,
      "policy_loss": 0.007137522962875664,
      "value_loss": 10220.40456085205,
      "entropy": 0.5057175314053893,
      "total_loss": 5110.2043533325195,
      "training_step": 58,
      "epoch": 57,
      "elapsed_time": 488.4431080818176
    },
    {
      "episodes_completed": 26,
      "mean_reward": 572.5305769230766,
      "std_reward": 592.3165483330404,
      "steps_collected": 2048,
      "policy_loss": 1.8393280333839358e-05,
      "value_loss": 13616.967778015136,
      "entropy": 0.6442406675778329,
      "total_loss": 6808.477461242675,
      "training_step": 59,
      "epoch": 58,
      "elapsed_time": 496.7028753757477
    },
    {
      "episodes_completed": 25,
      "mean_reward": 549.1671600000001,
      "std_reward": 625.1801312669292,
      "steps_collected": 2048,
      "policy_loss": 0.010977873799856753,
      "value_loss": 14386.589552307129,
      "entropy": 0.6498719899915159,
      "total_loss": 7193.2992492675785,
      "training_step": 60,
      "epoch": 59,
      "elapsed_time": 505.0484881401062
    },
    {
      "episodes_completed": 27,
      "mean_reward": 466.8066296296292,
      "std_reward": 467.7008646238131,
      "steps_collected": 2048,
      "policy_loss": 0.010892359571880662,
      "value_loss": 13446.672174072266,
      "entropy": 0.5875263249501586,
      "total_loss": 6723.341094970703,
      "training_step": 61,
      "epoch": 60,
      "elapsed_time": 515.7595572471619
    },
    {
      "episodes_completed": 31,
      "mean_reward": 360.3806451612903,
      "std_reward": 394.1113865245378,
      "steps_collected": 2048,
      "policy_loss": -0.001878920229501091,
      "value_loss": 13154.528219604492,
      "entropy": 0.569062490388751,
      "total_loss": 6577.256526184082,
      "training_step": 62,
      "epoch": 61,
      "elapsed_time": 524.2399673461914
    },
    {
      "episodes_completed": 17,
      "mean_reward": 947.5220588235292,
      "std_reward": 615.6453357537515,
      "steps_collected": 2048,
      "policy_loss": 0.010974843776784838,
      "value_loss": 10947.077015686034,
      "entropy": 0.6674509015865624,
      "total_loss": 5473.542831420898,
      "training_step": 63,
      "epoch": 62,
      "elapsed_time": 532.5290727615356
    },
    {
      "episodes_completed": 22,
      "mean_reward": 810.8602272727271,
      "std_reward": 511.54806101736926,
      "steps_collected": 2048,
      "policy_loss": 0.010029669266077689,
      "value_loss": 13185.004891967774,
      "entropy": 0.5822141909971833,
      "total_loss": 6592.506636810303,
      "training_step": 64,
      "epoch": 63,
      "elapsed_time": 540.8501148223877
    },
    {
      "episodes_completed": 30,
      "mean_reward": 515.6333333333332,
      "std_reward": 505.237029494298,
      "steps_collected": 2048,
      "policy_loss": 0.007752434944268316,
      "value_loss": 16696.67138366699,
      "entropy": 0.5646278425119817,
      "total_loss": 8348.337800598145,
      "training_step": 65,
      "epoch": 64,
      "elapsed_time": 549.2214965820312
    },
    {
      "episodes_completed": 27,
      "mean_reward": 517.2444074074072,
      "std_reward": 512.5535948213759,
      "steps_collected": 2048,
      "policy_loss": 0.0031165212509222328,
      "value_loss": 13545.948165893555,
      "entropy": 0.6585283519700169,
      "total_loss": 6772.970607757568,
      "training_step": 66,
      "epoch": 65,
      "elapsed_time": 557.5488920211792
    },
    {
      "episodes_completed": 37,
      "mean_reward": 393.91035135135127,
      "std_reward": 520.7418581079702,
      "steps_collected": 2048,
      "policy_loss": 0.012065770634217187,
      "value_loss": 14262.11171875,
      "entropy": 0.5893803455866873,
      "total_loss": 7131.062034606934,
      "training_step": 67,
      "epoch": 66,
      "elapsed_time": 565.85871052742
    },
    {
      "episodes_completed": 26,
      "mean_reward": 524.4292307692306,
      "std_reward": 473.5577606120995,
      "steps_collected": 2048,
      "policy_loss": -0.00015188330435194074,
      "value_loss": 12103.997732543945,
      "entropy": 0.6528859980404377,
      "total_loss": 6051.992169952393,
      "training_step": 68,
      "epoch": 67,
      "elapsed_time": 574.089656829834
    },
    {
      "episodes_completed": 23,
      "mean_reward": 550.210478260869,
      "std_reward": 483.9026459652418,
      "steps_collected": 2048,
      "policy_loss": 0.011461427577887661,
      "value_loss": 11431.324613952636,
      "entropy": 0.6179426305927336,
      "total_loss": 5715.667604064942,
      "training_step": 69,
      "epoch": 68,
      "elapsed_time": 582.4374475479126
    },
    {
      "episodes_completed": 29,
      "mean_reward": 460.8606206896552,
      "std_reward": 547.1883523718393,
      "steps_collected": 2048,
      "policy_loss": 0.006339405354810879,
      "value_loss": 11967.521217346191,
      "entropy": 0.6127918545156718,
      "total_loss": 5983.760832977295,
      "training_step": 70,
      "epoch": 69,
      "elapsed_time": 590.7878043651581
    },
    {
      "episodes_completed": 28,
      "mean_reward": 416.0662857142856,
      "std_reward": 441.36552793532985,
      "steps_collected": 2048,
      "policy_loss": 0.11756714402290527,
      "value_loss": 11004.815478515626,
      "entropy": 0.6174659186042846,
      "total_loss": 5502.519157409668,
      "training_step": 71,
      "epoch": 70,
      "elapsed_time": 599.269779920578
    },
    {
      "episodes_completed": 19,
      "mean_reward": 651.7202631578944,
      "std_reward": 543.3993810694071,
      "steps_collected": 2048,
      "policy_loss": 0.008136700952309183,
      "value_loss": 12011.509797668457,
      "entropy": 0.5828204931691289,
      "total_loss": 6005.757232666016,
      "training_step": 72,
      "epoch": 71,
      "elapsed_time": 607.9220206737518
    },
    {
      "episodes_completed": 21,
      "mean_reward": 565.1096666666665,
      "std_reward": 469.42000059002197,
      "steps_collected": 2048,
      "policy_loss": 0.005740129871992394,
      "value_loss": 11267.072494506836,
      "entropy": 0.5584683542139828,
      "total_loss": 5633.536396789551,
      "training_step": 73,
      "epoch": 72,
      "elapsed_time": 617.0431966781616
    },
    {
      "episodes_completed": 25,
      "mean_reward": 520.9501199999997,
      "std_reward": 426.5948445143065,
      "steps_collected": 2048,
      "policy_loss": 0.00889800006407313,
      "value_loss": 11177.13338317871,
      "entropy": 0.5508235845714807,
      "total_loss": 5588.570083618164,
      "training_step": 74,
      "epoch": 73,
      "elapsed_time": 626.543425321579
    },
    {
      "episodes_completed": 22,
      "mean_reward": 556.6284999999997,
      "std_reward": 539.8253119708555,
      "steps_collected": 2048,
      "policy_loss": 0.005022639146773145,
      "value_loss": 9946.823118591308,
      "entropy": 0.583885233476758,
      "total_loss": 4973.410757446289,
      "training_step": 75,
      "epoch": 74,
      "elapsed_time": 634.848326921463
    },
    {
      "episodes_completed": 22,
      "mean_reward": 600.1536363636361,
      "std_reward": 545.138330567868,
      "steps_collected": 2048,
      "policy_loss": 0.002529540000250563,
      "value_loss": 10212.918103027343,
      "entropy": 0.6528695974498987,
      "total_loss": 5106.455054473877,
      "training_step": 76,
      "epoch": 75,
      "elapsed_time": 643.1198556423187
    },
    {
      "episodes_completed": 28,
      "mean_reward": 459.7211071428568,
      "std_reward": 478.1275567024331,
      "steps_collected": 2048,
      "policy_loss": 0.015349455093382858,
      "value_loss": 14207.594459533691,
      "entropy": 0.6536703474819661,
      "total_loss": 7103.806043243409,
      "training_step": 77,
      "epoch": 76,
      "elapsed_time": 651.3593490123749
    },
    {
      "episodes_completed": 18,
      "mean_reward": 669.0381111111112,
      "std_reward": 624.2400395929345,
      "steps_collected": 2048,
      "policy_loss": 0.01143104954098817,
      "value_loss": 11836.462562561035,
      "entropy": 0.5804698907770216,
      "total_loss": 5918.236898803711,
      "training_step": 78,
      "epoch": 77,
      "elapsed_time": 659.7146527767181
    },
    {
      "episodes_completed": 22,
      "mean_reward": 541.2823636363636,
      "std_reward": 556.731227329714,
      "steps_collected": 2048,
      "policy_loss": 0.00654945332207717,
      "value_loss": 11366.306491088868,
      "entropy": 0.5433319593779743,
      "total_loss": 5683.154354858399,
      "training_step": 79,
      "epoch": 78,
      "elapsed_time": 667.958922624588
    },
    {
      "episodes_completed": 25,
      "mean_reward": 583.9600799999998,
      "std_reward": 588.0534671690949,
      "steps_collected": 2048,
      "policy_loss": 0.007033082234556787,
      "value_loss": 13672.58291015625,
      "entropy": 0.6572799736633896,
      "total_loss": 6836.2919052124025,
      "training_step": 80,
      "epoch": 79,
      "elapsed_time": 676.2068800926208
    },
    {
      "episodes_completed": 28,
      "mean_reward": 481.06924999999984,
      "std_reward": 514.8610137834442,
      "steps_collected": 2048,
      "policy_loss": 0.0015170232945820317,
      "value_loss": 13587.489962768555,
      "entropy": 0.5911220676265657,
      "total_loss": 6793.740591430664,
      "training_step": 81,
      "epoch": 80,
      "elapsed_time": 688.5684387683868
    },
    {
      "episodes_completed": 17,
      "mean_reward": 889.7601764705878,
      "std_reward": 473.116123335765,
      "steps_collected": 2048,
      "policy_loss": 0.013975306702195666,
      "value_loss": 10190.5833984375,
      "entropy": 0.6161904146894812,
      "total_loss": 5095.299517822265,
      "training_step": 82,
      "epoch": 81,
      "elapsed_time": 697.270081281662
    },
    {
      "episodes_completed": 32,
      "mean_reward": 352.9119687499999,
      "std_reward": 480.7703989778725,
      "steps_collected": 2048,
      "policy_loss": 0.017169277332141065,
      "value_loss": 12948.673393249512,
      "entropy": 0.5801541431806981,
      "total_loss": 6474.348056793213,
      "training_step": 83,
      "epoch": 82,
      "elapsed_time": 705.6743869781494
    },
    {
      "episodes_completed": 23,
      "mean_reward": 589.8761304347826,
      "std_reward": 574.0823700883006,
      "steps_collected": 2048,
      "policy_loss": 0.0020236134965671226,
      "value_loss": 13314.152471923828,
      "entropy": 0.5146454775705933,
      "total_loss": 6657.073148345948,
      "training_step": 84,
      "epoch": 83,
      "elapsed_time": 714.1837515830994
    },
    {
      "episodes_completed": 21,
      "mean_reward": 638.9915714285713,
      "std_reward": 615.9705289291016,
      "steps_collected": 2048,
      "policy_loss": 0.014549381070537493,
      "value_loss": 12926.876910400391,
      "entropy": 0.6050938149914146,
      "total_loss": 6463.446942901612,
      "training_step": 85,
      "epoch": 84,
      "elapsed_time": 722.4939403533936
    },
    {
      "episodes_completed": 20,
      "mean_reward": 895.0169,
      "std_reward": 747.3712877413008,
      "steps_collected": 2048,
      "policy_loss": 0.004867436763015575,
      "value_loss": 12416.874801635742,
      "entropy": 0.5509979808703065,
      "total_loss": 6208.4367576599125,
      "training_step": 86,
      "epoch": 85,
      "elapsed_time": 730.7837584018707
    },
    {
      "episodes_completed": 20,
      "mean_reward": 735.2198499999997,
      "std_reward": 738.3492044212737,
      "steps_collected": 2048,
      "policy_loss": 0.0031784530787263066,
      "value_loss": 12767.545834350585,
      "entropy": 0.6070822870358825,
      "total_loss": 6383.770027923584,
      "training_step": 87,
      "epoch": 86,
      "elapsed_time": 739.1250467300415
    },
    {
      "episodes_completed": 20,
      "mean_reward": 694.0898499999998,
      "std_reward": 553.4094835089363,
      "steps_collected": 2048,
      "policy_loss": 0.009822059051657561,
      "value_loss": 15194.376313781739,
      "entropy": 0.5334952106699348,
      "total_loss": 7597.192640686035,
      "training_step": 88,
      "epoch": 87,
      "elapsed_time": 747.4517242908478
    },
    {
      "episodes_completed": 20,
      "mean_reward": 727.2048499999996,
      "std_reward": 609.61365662748,
      "steps_collected": 2048,
      "policy_loss": 0.010941277106758207,
      "value_loss": 16963.97557067871,
      "entropy": 0.4210711064748466,
      "total_loss": 8481.99451751709,
      "training_step": 89,
      "epoch": 88,
      "elapsed_time": 755.6698834896088
    },
    {
      "episodes_completed": 17,
      "mean_reward": 780.3606470588235,
      "std_reward": 566.9559684292275,
      "steps_collected": 2048,
      "policy_loss": -0.009537835163064301,
      "value_loss": 14012.284020996094,
      "entropy": 0.3561370723415166,
      "total_loss": 7006.128886413574,
      "training_step": 90,
      "epoch": 89,
      "elapsed_time": 763.9497702121735
    },
    {
      "episodes_completed": 22,
      "mean_reward": 654.017090909091,
      "std_reward": 631.1109946661102,
      "steps_collected": 2048,
      "policy_loss": 0.014001035926048644,
      "value_loss": 13617.517601013184,
      "entropy": 0.44653639746829865,
      "total_loss": 6808.768332672119,
      "training_step": 91,
      "epoch": 90,
      "elapsed_time": 772.5727655887604
    },
    {
      "episodes_completed": 23,
      "mean_reward": 678.8456521739132,
      "std_reward": 712.7878254175865,
      "steps_collected": 2048,
      "policy_loss": 0.008620561863062903,
      "value_loss": 18184.997024536133,
      "entropy": 0.5257668511010707,
      "total_loss": 9092.50185546875,
      "training_step": 92,
      "epoch": 91,
      "elapsed_time": 781.0484480857849
    },
    {
      "episodes_completed": 18,
      "mean_reward": 820.8727777777774,
      "std_reward": 546.3816406040495,
      "steps_collected": 2048,
      "policy_loss": 0.014582673291442916,
      "value_loss": 14557.8383102417,
      "entropy": 0.5911777753382921,
      "total_loss": 7278.927822113037,
      "training_step": 93,
      "epoch": 92,
      "elapsed_time": 789.3059794902802
    },
    {
      "episodes_completed": 23,
      "mean_reward": 614.1493478260869,
      "std_reward": 665.1901257490622,
      "steps_collected": 2048,
      "policy_loss": 0.01090902671276126,
      "value_loss": 17254.36069946289,
      "entropy": 0.6721589596942067,
      "total_loss": 8627.184535217286,
      "training_step": 94,
      "epoch": 93,
      "elapsed_time": 797.6115989685059
    },
    {
      "episodes_completed": 34,
      "mean_reward": 321.1854117647058,
      "std_reward": 276.6208175066831,
      "steps_collected": 2048,
      "policy_loss": 0.0037024949619080872,
      "value_loss": 15592.242875671387,
      "entropy": 0.6148777657188476,
      "total_loss": 7796.118993377686,
      "training_step": 95,
      "epoch": 94,
      "elapsed_time": 805.8838558197021
    },
    {
      "episodes_completed": 30,
      "mean_reward": 441.04316666666637,
      "std_reward": 429.4558644601389,
      "steps_collected": 2048,
      "policy_loss": 0.007549987273523584,
      "value_loss": 12876.614367675782,
      "entropy": 0.6879466485232115,
      "total_loss": 6438.307859802246,
      "training_step": 96,
      "epoch": 95,
      "elapsed_time": 814.2082641124725
    },
    {
      "episodes_completed": 29,
      "mean_reward": 451.30648275862046,
      "std_reward": 467.84311806369453,
      "steps_collected": 2048,
      "policy_loss": 0.0020279458723962305,
      "value_loss": 13273.230035400391,
      "entropy": 0.6975471045821905,
      "total_loss": 6636.610052490234,
      "training_step": 97,
      "epoch": 96,
      "elapsed_time": 822.4483587741852
    },
    {
      "episodes_completed": 13,
      "mean_reward": 1146.0366153846153,
      "std_reward": 436.36076490472533,
      "steps_collected": 2048,
      "policy_loss": 0.008516015580971726,
      "value_loss": 11033.60238494873,
      "entropy": 0.7330070348456502,
      "total_loss": 5516.802367401123,
      "training_step": 98,
      "epoch": 97,
      "elapsed_time": 830.7008957862854
    },
    {
      "episodes_completed": 20,
      "mean_reward": 558.8222499999997,
      "std_reward": 382.33561353448016,
      "steps_collected": 2048,
      "policy_loss": 0.01012523777608294,
      "value_loss": 9713.881533050537,
      "entropy": 0.7921912919729948,
      "total_loss": 4856.942980194091,
      "training_step": 99,
      "epoch": 98,
      "elapsed_time": 838.9621078968048
    },
    {
      "episodes_completed": 31,
      "mean_reward": 527.6896129032258,
      "std_reward": 517.5220130170983,
      "steps_collected": 2048,
      "policy_loss": 0.0050669396063312885,
      "value_loss": 12364.061315917968,
      "entropy": 0.7915012450888753,
      "total_loss": 6182.027799224854,
      "training_step": 100,
      "epoch": 99,
      "elapsed_time": 847.2200684547424
    }
  ],
  "evaluation": [
    {
      "mean_reward": 230.82899999999995,
      "std_reward": 222.1268303672474,
      "mean_length": 60.7,
      "min_reward": -2.2,
      "max_reward": 666.0499999999992,
      "epoch": 19
    },
    {
      "mean_reward": 135.7,
      "std_reward": 115.17367320703106,
      "mean_length": 38.2,
      "min_reward": -2.6999999999999997,
      "max_reward": 406.29999999999967,
      "epoch": 39
    },
    {
      "mean_reward": 276.8399999999997,
      "std_reward": 222.0677642072341,
      "mean_length": 70.8,
      "min_reward": -3.7500000000000004,
      "max_reward": 755.9499999999978,
      "epoch": 59
    },
    {
      "mean_reward": 944.6088000000005,
      "std_reward": 644.2983673404433,
      "mean_length": 140.6,
      "min_reward": -1.0,
      "max_reward": 2272.7860000000005,
      "epoch": 79
    },
    {
      "mean_reward": 584.2425,
      "std_reward": 454.8234305818577,
      "mean_length": 96.1,
      "min_reward": -39.250000000000014,
      "max_reward": 1347.3749999999998,
      "epoch": 99
    }
  ]
}